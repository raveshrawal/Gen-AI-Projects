{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vat6PB-dyjym",
        "outputId": "b3f5be50-8073-4bab-9ed3-a7e095832c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain[groq] in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (0.4.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (6.0.2)\n",
            "Collecting langchain-groq (from langchain[groq])\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[groq]) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[groq]) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[groq]) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[groq]) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[groq]) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[groq]) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[groq]) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[groq]) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[groq]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[groq]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[groq]) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[groq]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[groq]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[groq]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[groq]) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain[groq]) (3.2.4)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq->langchain[groq])\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq->langchain[groq]) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq->langchain[groq]) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq->langchain[groq]) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[groq]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[groq]) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain[groq]) (3.0.0)\n",
            "Downloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.31.1 langchain-groq-0.3.8\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv langchain[groq]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_KEY')"
      ],
      "metadata": {
        "id": "tw2kpWr2ylAp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\")"
      ],
      "metadata": {
        "id": "DqGyU0Xkzrvs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(\"Hello, explain me CNN!\")"
      ],
      "metadata": {
        "id": "xMhspzRszsPH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "hSPAL4s9zu7S",
        "outputId": "00a6b2d2-7a5f-4872-d7cd-db1d5921d184"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"**Convolutional Neural Networks (CNNs)**\\n======================================\\n\\nConvolutional Neural Networks (CNNs) are a type of deep learning model that are widely used for image and video processing tasks. They are particularly effective for tasks such as image classification, object detection, and image segmentation.\\n\\n**Architecture of a CNN**\\n------------------------\\n\\nA CNN typically consists of the following layers:\\n\\n1. **Convolutional Layers**: These layers apply a set of filters to the input image, scanning it pixel by pixel to produce feature maps. Each filter is essentially a small kernel that slides over the input image to extract local features.\\n2. **Activation Functions**: These layers apply an activation function to the output of the convolutional layers to introduce non-linearity and enable the network to learn more complex features.\\n3. **Pooling Layers**: These layers reduce the spatial dimensions of the feature maps by taking the maximum or average value across each region, helping to reduce the number of parameters and improve translation invariance.\\n4. **Flatten Layer**: This layer flattens the output of the convolutional and pooling layers into a one-dimensional array, which is then fed into the fully connected layers.\\n5. **Fully Connected Layers**: These layers are similar to those used in traditional neural networks and consist of fully connected neurons that process the flattened feature maps to produce the final output.\\n\\n**How CNNs Work**\\n----------------\\n\\nHere's a step-by-step explanation of how CNNs work:\\n\\n1. **Input Layer**: The input image is fed into the network.\\n2. **Convolutional Layer**: A set of filters is applied to the input image to produce a feature map.\\n3. **Activation Function**: The activation function is applied to the output of the convolutional layer to introduce non-linearity.\\n4. **Pooling Layer**: The feature map is passed through a pooling layer to reduce the spatial dimensions.\\n5. **Flatten Layer**: The output of the convolutional and pooling layers is flattened into a one-dimensional array.\\n6. **Fully Connected Layers**: The flattened array is passed through one or more fully connected layers to produce the final output.\\n\\n**Advantages of CNNs**\\n----------------------\\n\\n1. **Translation Invariance**: CNNs are able to learn features that are invariant to translation, which means that they can recognize objects even if they are moved or rotated.\\n2. **Robust to Deformations**: CNNs are able to learn features that are robust to deformations, which means that they can recognize objects even if they are slightly distorted.\\n3. **Reduced Number of Parameters**: CNNs have a reduced number of parameters compared to traditional neural networks, which makes them less prone to overfitting.\\n\\n**Example Use Cases**\\n----------------------\\n\\n1. **Image Classification**: CNNs can be used for image classification tasks such as classifying images into different categories (e.g. cats vs dogs).\\n2. **Object Detection**: CNNs can be used for object detection tasks such as detecting objects in an image (e.g. detecting cars in a parking lot).\\n3. **Image Segmentation**: CNNs can be used for image segmentation tasks such as segmenting an image into different regions (e.g. segmenting an image of a person into different body parts).\\n\\n**Code Example**\\n----------------\\n\\nHere's an example of how to implement a basic CNN using Keras:\\n```python\\nfrom keras.models import Sequential\\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\\n\\n# Define the model\\nmodel = Sequential()\\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\\nmodel.add(MaxPooling2D((2, 2)))\\nmodel.add(Flatten())\\nmodel.add(Dense(64, activation='relu'))\\nmodel.add(Dense(10, activation='softmax'))\\n\\n# Compile the model\\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\\n\\n# Train the model\\nmodel.fit(X_train, y_train, epochs=10, batch_size=128)\\n```\\nThis code defines a basic CNN model with two convolutional layers, one max pooling layer, one flatten layer, and two fully connected layers. The model is then compiled and trained on the training data.\\n\\nNote: This is a simplified example and you may need to adjust the architecture and hyperparameters based on your specific use case.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}